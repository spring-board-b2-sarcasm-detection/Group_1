{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b9fc2b0-27bf-465a-b186-2a72860fbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07151023-3512-4865-b3ab-655826ae192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\guded\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ensure stopwords are downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a18613de-bd68-4270-9784-8688bb6a3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_text(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "#tokenise the cleaned text column\n",
    "tokenized_text = df['cleaned_text'].apply(tokenize_text).tolist()\n",
    "\n",
    "# Train a Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to vectorize a sentence using Word2Vec\n",
    "def vectorize_sentence(sentence, model):\n",
    "    vec = np.zeros(model.vector_size)\n",
    "    count = 0\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            vec += model.wv[word]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "# Create an empty list to store embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Iterate over each tokenized comment and compute embeddings\n",
    "for tokens in tokenized_text:\n",
    "    embeddings.append(vectorize_sentence(tokens, word2vec_model))\n",
    "\n",
    "# Assign embeddings to a new column in DataFrame\n",
    "df['word2vec_embeddings'] = embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66d5ab1a-d292-4f46-9b38-7385ded08900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>word2vec_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>nc and nh.</td>\n",
       "      <td>[0.14374949348469576, 0.7420615972951055, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>you do know west teams play against west teams...</td>\n",
       "      <td>[0.615642111748457, 1.3846457180167948, -0.235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>they were underdogs earlier today, but since g...</td>\n",
       "      <td>[0.1102830532595123, 1.0217785915653956, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "      <td>this meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>[0.30669022041062516, 0.555068398360163, 0.357...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "      <td>i could use one of those tools.</td>\n",
       "      <td>[-0.3392863614218576, 1.704587070537465, -0.16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  score  ups  \\\n",
       "0      0                                         NC and NH.      2   -1   \n",
       "1      0  You do know west teams play against west teams...     -4   -1   \n",
       "2      0  They were underdogs earlier today, but since G...      3    3   \n",
       "3      0  This meme isn't funny none of the \"new york ni...     -8   -1   \n",
       "4      0                    I could use one of those tools.      6   -1   \n",
       "\n",
       "   downs                                     parent_comment  \\\n",
       "0     -1  Yeah, I get that argument. At this point, I'd ...   \n",
       "1     -1  The blazers and Mavericks (The wests 5 and 6 s...   \n",
       "2      0                            They're favored to win.   \n",
       "3     -1                         deadass don't kill my buzz   \n",
       "4     -1  Yep can confirm I saw the tool they use for th...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0                                         nc and nh.   \n",
       "1  you do know west teams play against west teams...   \n",
       "2  they were underdogs earlier today, but since g...   \n",
       "3  this meme isn't funny none of the \"new york ni...   \n",
       "4                    i could use one of those tools.   \n",
       "\n",
       "                                 word2vec_embeddings  \n",
       "0  [0.14374949348469576, 0.7420615972951055, -0.3...  \n",
       "1  [0.615642111748457, 1.3846457180167948, -0.235...  \n",
       "2  [0.1102830532595123, 1.0217785915653956, -0.00...  \n",
       "3  [0.30669022041062516, 0.555068398360163, 0.357...  \n",
       "4  [-0.3392863614218576, 1.704587070537465, -0.16...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  #Dataset containing Encoded data using word2vec encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd35683-f927-4fce-babc-bf3356230959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:\\\\Users\\\\guded\\\\OneDrive\\\\Desktop\\\\INFOSYS\\\\train-balanced-sarcasm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ab3ba-48f1-4801-8718-7d55617570ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
