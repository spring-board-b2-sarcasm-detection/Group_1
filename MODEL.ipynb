{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f67483-d462-4176-8191-c78f9535acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af6a499-dd3f-4925-805a-264f5fbab0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\guded\\\\OneDrive\\\\Desktop\\\\INFOSYS\\\\train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b163cb-52ee-447f-87e9-e8ff779ca193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to clean and convert embeddings from strings to numpy arrays\n",
    "def clean_and_convert_embedding(embedding_str):\n",
    "    try:\n",
    "        # Ensure the string is properly formatted with commas between numbers\n",
    "        clean_str = embedding_str.replace('\\n', ' ').replace('[ ', '[').replace(' ]', ']').replace('  ', ' ')\n",
    "        clean_str = ','.join(clean_str.split())  # Ensure commas are placed correctly\n",
    "        return np.array(ast.literal_eval(clean_str))\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing embedding: {embedding_str}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e27ebda-58b3-4986-b322-53add336a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the helper function to the DataFrame\n",
    "df['word2vec_embeddings'] = df['word2vec_embeddings'].apply(clean_and_convert_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7820a0c9-8840-434f-b2c4-9be67f8624ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [-0.249028446, -0.112276957, -0.00595155568, 0...\n",
      "1    [-0.06435088, -0.14805339, 0.32883312, 0.62132...\n",
      "2    [0.1968625, 0.05365723, 0.03638186, 0.10795132...\n",
      "3    [-0.14819673, 0.18820012, 0.08938915, 0.426148...\n",
      "4    [0.21537142, 0.49409585, 1.07777257, 0.8793004...\n",
      "Name: word2vec_embeddings, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verify the conversion\n",
    "print(df['word2vec_embeddings'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3569c7e-487a-4513-8582-e50d62c03c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset of the dataset\n",
    "df_sampled = df.sample(n=10000, random_state=42)  # Adjust the sample size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d545b57-9582-4437-9ecd-ea7f24142e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = np.vstack(df_sampled['word2vec_embeddings'].values)\n",
    "y = df_sampled['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ed2c6e-8993-4621-9bad-8ff1bfe6d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the embeddings using PCA\n",
    "pca = PCA(n_components=20)  # Further reduce the number of components\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8c308f-3ef4-4aaa-b5ba-02d544446010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "917dcd99-a49b-4b57-8fdd-7a6abb189042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression classifier\n",
    "log_reg_classifier = LogisticRegression(max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fe8909-8f4d-4dd5-9e35-d6274f30a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the time taken to train the Logistic Regression classifier\n",
    "start_time = time.time()\n",
    "log_reg_classifier.fit(X_train, y_train)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a775e46-5fad-4759-899a-3e266402dc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.023777484893798828 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training time: {training_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71de709-01d1-4dae-8cda-c7b9963835f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = log_reg_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b3ac22e-9f82-49b4-b544-03d36918ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "357fac04-761b-4a04-81fa-7e73936483fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6165\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e40a93-e3e2-4baa-95d8-4c129f791b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71      1127\n",
      "           1       0.60      0.35      0.45       873\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.61      0.59      0.58      2000\n",
      "weighted avg       0.61      0.62      0.59      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6b2947-c186-4c42-b5b2-6394bc0eee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      " [[925 202]\n",
      " [565 308]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d1ed0-ccab-413f-aa8c-fb6a89f7eb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
